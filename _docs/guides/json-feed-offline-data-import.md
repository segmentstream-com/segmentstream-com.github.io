---
layout: page
section: guides
navigation_title: "Importing offline data using JSON feed"
title: "Importing offline data using JSON feed"
date: 2020-05-08
---

<ul class="page-navigation">
  <li><a href="#before-you-begin">Before you begin</a></li>
  <li><a href="#creating-feed">Creating JSON feed</a>
    <ul>
      <li><a href="#feed-requirements">Feed requirements</a></li>
      <li><a href="#feed-example">Transaction feed example</a></li>
      <li><a href="#crm-data-example">CRM data example</a></li>
      <li><a href="#all-orders">Approach 1: All CRM orders</a></li>
      <li><a href="#daily-updates">Approach 2: Daily order updates</a></li>
    </ul>
  </li>
  <li><a href="#enabling-feed-import">Enabling feed import in SegmentStream</a></li>
  <li><a href="#next">What's next</a></li>
</ul>
This document describes how to import offline data from the CRM (i.e. sales or leads statuses) into BigQuery using JSON feed.

Imported offline data can be combined with other website data to improve ROI reporting and attribution by optimising not only based on online transactions but on final order/lead statuses in the CRM.

## <a name="before-you-begin"></a> Before you begin
* Make sure that [BigQuery is connected to SegmentStream](/_docs/bigquery/connecting-bigquery).

## <a name="creating-feed"></a>Creating JSON feed

SegmentStream can download feeds in JSON format and import its' content into Google BigQuery.

### <a name="#feed-requirements"></a>Feed requirements
* The feed should be generated by the customer’s server and be available at a specific URL, for example, `https://example.com/feed.json`.
* The feed should be in [NDJSON (new line delimeted JSON) format](http://ndjson.org/).
* We highly recommend implementing [Basic Auth](https://en.wikipedia.org/wiki/Basic_access_authentication) to protect the feed from being publicly exposed.
* (Optional, recommended) It should be possible to fetch daily feed data using date parameter added to the feed URL.<br/>
**For example**, the feed with the URL `https://example.com/feed.json?date=20200101` should display transactions updates for the 1st of January 2020
This way instead of importing all transactions, only daily updates will be imported. This approach will be explained later on in this guide.

### <a name="crm-data-example"></a>CRM data example

Imagine, you have the following data in your CRM:

createdAt | updatedAt | orderId | status | total | currency | userId
--- | --- | --- | --- | --- | --- | ---
2020-01-10| 2020-01-15 | N1 | USD | 120.13 | delivered | U1
2020-01-15| 2020-01-20 | N2 | USD | 96.12 | refunded | U2
2020-01-20| 2020-01-20 | N3 | USD | 299.99 | received | U3

Where:
* `createdAt` - time of the order creation in ISO 8601 standard
* `updatedAt` - time of the latest order status update in ISO 8601
* `orderId` - unique identifier of the order in your CRM system or website database. For other businesses it might be `leadId` or any other unique record identifier.
* `currency` - order currency code
* `total` - Total cost of the order
* `status` - The most recent order status (e.g. `received`, `shipped`, `delivered`, `refunded`, etc)
* `userId` - unique identifier of the user that made an order

> Note: the structure is provided as a reference, you can add any other fields you need.

There are two different approaches how this CRM data can be exported to the NDJSON feed.

### <a name="#all-orders"></a> Approach 1: Feed contains the snapshot of all orders/leads from the CRM with it's current statuses
Implementation of this approach will lead to full data overwrite every day with the new data. You feed may contain either all order/leads from the CRM or orders/leads for the last year.

This approach is simple to implement, but will lead to the overhead in terms of lots of data transfer which might be not applicable if you have many transactions per day.

#### Sample feed data

Line|Feed record|
--- | --- |
1 | `{"orderId":"N1", "createdAt":"2020-01-10","updatedAt":"2020-01-15","currency":"USD","total":120.13,"status":"delivered","userId":"U1"}`
2 | `{"orderId":"N2", "createdAt":"2020-01-15","updatedAt":"2020-01-20", "currency":"USD","total":96.12,"status":"shipped","userId":"U2"}`
3| `{"orderId":"N3", "createdAt":"2020-01-20","updatedAt":"2020-01-20", "currency":"USD","total":299.99,"status":"pendingShipment","userId":"U3"}`

> **Notice** that feed contains different `updatedAt` values and absolutely all records from the CRM.

### <a name="#daily-updates"></a> Approach 2: Feed contains only orders/leads that were updated during the day

If you choose to implement this option you should parse `date` query parameter of the feed request and respond only with necessary update records. For example, if request is `https://example.com?date=20200120`, you should return only CRM records that were updated 20th of Jan, 2020.

#### Sample feed data

Line|Feed record|
--- | --- |
1 | `{"orderId":"N2", "createdAt":"2020-01-15","updatedAt":"2020-01-20", "currency":"USD","total":96.12,"status":"shipped","userId":"U2"}`
2| `{"orderId":"N3", "createdAt":"2020-01-20","updatedAt":"2020-01-20", "currency":"USD","total":299.99,"status":"pendingShipment","userId":"U3"}`

> Note: This approach allows to significantly reduce the bandwidth by importing only order updates instead of all CRM orders.

Your order feed should contain update records, meaning that for each change in the status of existing transaction you create a new record in the feed with the new value of the `updatedAt` field and preserving the value of the `createdAt` field.

 
## <a name="enabling-feed-import"></a>Enabling "JSON Feed" data source
1. Go to [SegmentStream admin panel▸](https://admin.segmentstream.com).
2. Open **Data Sources ▸ Add Data Source**.
3. Select **JSON Feed**.
4. Fill login and password for you Basic Auth credentials (if you decided not to implement Basic Auth you can enter any values).
5. In the **Feed URL** field specify the URL where your feed can be found (don't enter `date` query param parameter).
6. In the **Destination table name** field specify the BigQuery table name that will contain imported feed data.
7. Enable **Partition table by date** option if you decided to use [Approach 2](#daily-updates) for the feed generation (recommended).

### <a name="#how-feed-import-works"></a> How feed import works

Everyday SegmentStream fetches data from the specified feed URL using provided credentials and appending.

If you enabled **Partition table by date** option, an additional `date` query parameter with the value `YYYYMMDD` will be added to the URL, where:
* `YYYY` - current year;
* `MM` - current month;
* `DD` - current date;

Example request as of 20 Jan, 2020 when **Partition table by date** is disabled:

`GET https://example.com/feed.json`

Example request as of 20 Jan, 2020 when **Partition table by date** is disabled:

`GET https://example.com/feed.json?date=20200120`

## <a name="next"></a>What's next

During the next 24 hours your feed data will be uploaded to the corresponding BigQuery table.
