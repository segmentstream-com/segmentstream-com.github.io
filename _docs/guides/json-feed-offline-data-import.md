---
layout: page
section: guides
navigation_title: "Importing transactions or leads using JSON feed"
title: "Importing transactions or leads using JSON feed"
date: 2020-05-08
---

<ul class="page-navigation">
  <li><a href="#before-you-begin">Before you begin</a></li>
  <li><a href="#creating-feed">Step 1: Creating JSON feed</a>
    <ul>
      <li><a href="#feed-requirements">Feed requirements</a></li>
      <li><a href="#all-orders">Approach 1: all orders</a></li>
      <li><a href="#daily-updates">Approach 2: daily updates</a></li>
      <li><a href="#sample-feeds">Sample feeds</a></li>
    </ul>
  </li>
  <li><a href="#enabling-feed-import">Step 2: Enabling feed import in SegmentStream</a></li>
</ul>
This document describes how to import offline data (transactions or leads) into BigQuery using JSON feed.

SegmentStream is a platform that allows you to automatically collect marketing data from all your sources to BigQuery to enable advanced ROI reporting & attribution. 

Importing offline transactions can be used with other website data to improve ROI reporting.

## <a name="before-you-begin"></a> Before you begin
Before creating and importing a JSON feed to BigQuery, first:
* Make sure that BigQuery is Connected to SegmentStream

## <a name="creating-feed"></a> Step 1: Creating JSON feed 

SegmentStream can download feeds in JSON format and import their content into Google BigQuery.

### Feed requirements
* The feed should be generated by the customer’s back-end and be available at a specific URL, for example, https://example.com/feed.json

* The feed should be in [Newline Delimited JSON file format](http://ndjson.org/).

* We highly recommend implementing [basic Auth](https://en.wikipedia.org/wiki/Basic_access_authentication) to protect feed from being publicly exposed
* (Optional, recommended) It should be possible to fetch daily feed data using date parameter added to the feed URL
Example:
https://example.com/feed.json?date=20200101 - displays feed data for 1st of January 2020
This way instead of importing all transactions, only daily updates will be imported. This approach will be explained later on in this guide.

### How feed import works
Every day SegmentStream fetches data from the specified feed URL using credentials provided and appending **date** parameter to the  URL.
**date** parameter is formatted as YYYYMMDD meaning that first 4 numbers - current year, next 2 - month, last 2 - date.

Example of the possible feed request as of 9 May 2020: 
https://example.com/feed.json?**date=20200509**

You can implement one of the options regarding returning feed data on request:

#### Option 1: Returning all of the order records on each feed request
To ensure that by the time SegmentStream fetches order records they are already uploaded it's better to update feed data constantly.
Sample feed: 

```ndjson
{"createdAt":"2020-01-19T20:00:20.202Z","updatedAt":"2020-01-20T20:00:20.202Z","orderId":"100","currency":"USD","total":120.13,"status":"created","userId":"4af3ce14-e8ab-4c7a-907d-3848e6bdb7cf"}
{"createdAt":"2020-01-19T20:00:20.202Z","updatedAt":"2020-01-21T05:03:15.661Z","orderId":"100","currency":"USD","total":120.13,"status":"shipped","userId":"4af3ce14-e8ab-4c7a-907d-3848e6bdb7cf"}
{"createdAt":"2020-01-19T10:53:40.591Z","updatedAt":"2020-01-22T18:15:34.031Z","orderId":"73","currency":"USD","total":299.99,"status":"pendingShipment","userId":"dee3ca08-27de-495c-8738-060029a58449"}
```

> Notice that feed contains different "updatedAt" dates (from 20th to 22th Jan 2020).

#### date parameter processing:

If you implement this option you don't need to check the value of the date parameter as for every date value you should return all of the order records.

#### Option 2: Returning daily feed updates data partitioned by day based on date parameter value
If you choose to implement this option you should implement date parameter processing.

#### date parameter processing:

You should parse date GET parameter of the feed request and respond only with necessary update records.
e.g. if request is https://example.com?date=20200120
you should return only records that were made on the 20th Jan 2020:

```ndjson
{"createdAt":"2020-01-20T20:00:20.202Z","updatedAt":"2020-01-20T20:00:20.202Z","orderId":"100","currency":"USD","total":120.13,"status":"created","userId":"4af3ce14-e8ab-4c7a-907d-3848e6bdb7cf"}
{"createdAt":"2020-01-19T06:56:12.554Z","updatedAt":"2020-01-20T20:02:01.301Z","orderId":"50","currency":"USD","total":96.12,"status":"shipped","userId":"86116bb2-716b-4762-bc38-82417e69f7a1"}
{"createdAt":"2020-01-19T10:53:40.591Z","updatedAt":"2020-01-20T20:02:02.711Z","orderId":"73","currency":"USD","total":299.99,"status":"pendingShipment","userId":"dee3ca08-27de-495c-8738-060029a58449"}
```


> Note: This approach allows you to reduce BigQuery costs when implementing ROI reporting as SegmentStream would only request data for the required date period, instead of requesting the whole feed table.

### Feed contents
Your order feed should contain update records, meaning that for each change in the order status you create a new record in the feed with the new value of the "updatedAt" field and preserving the value of the "createdAt" field.

**Example:**
Order was created on the 19th Jan 2020 and later it was shipped on the 20th Jan 2020.
It should be reflected in the feed the following way:
**Note: this is not valid NDJSON as it contains comments.**

```ndjson
{"createdAt":"2020-01-20T20:00:20.202Z","updatedAt":"2020-01-20T20:00:20.202Z","orderId":"100","currency":"USD","total":120.13,"status":"created","userId":"4af3ce14-e8ab-4c7a-907d-3848e6bdb7cf"} // order 100 was created at 2020-01-20
{"createdAt":"2020-01-20T20:00:20.202Z","updatedAt":"2020-01-21T17:02:01.301Z","orderId":"50","currency":"USD","total":96.12,"status":"shipped","userId":"86116bb2-716b-4762-bc38-82417e69f7a1"} // order 100 was shipped at 2020-01-21
```

### Ecommerce order feed example (formatted JSON version)
Note: This feed is JSON formatted - not NDJSON - don't format your feed like this.
```json
[{
    "createdAt": "2020-01-20T20:00:20.202Z",
    "updatedAt": "2020-01-20T20:00:20.202Z",
    "orderId": "100",
    "currency": "USD",
    "total": 120.13,
    "status": "created",
    "userId":"4af3ce14-e8ab-4c7a-907d-3848e6bdb7cf"
},
{
    "createdAt": "2020-01-19T06:56:12.554Z",
    "updatedAt": "2020-01-20T20:02:01.301Z",
    "orderId": "50",
    "currency": "USD",
    "total": 96.12,
    "status": "shipped",
    "userId":"86116bb2-716b-4762-bc38-82417e69f7a1"
},
{
    "createdAt": "2020-01-19T10:53:40.591Z",
    "updatedAt": "2020-01-20T20:02:02.711Z",
    "orderId": "73",
    "currency": "USD",
    "total": 299.99,
    "status": "pendingShipment",
    "userId":"dee3ca08-27de-495c-8738-060029a58449"
}]
```

The previous feed looks like this when formatted in NDJSON format:
```ndjson
{"createdAt":"2020-01-20T20:00:20.202Z","updatedAt":"2020-01-20T20:00:20.202Z","orderId":"100","currency":"USD","total":120.13,"status":"created","userId":"4af3ce14-e8ab-4c7a-907d-3848e6bdb7cf"}
{"createdAt":"2020-01-19T06:56:12.554Z","updatedAt":"2020-01-20T20:02:01.301Z","orderId":"50","currency":"USD","total":96.12,"status":"shipped","userId":"86116bb2-716b-4762-bc38-82417e69f7a1"}
{"createdAt":"2020-01-19T10:53:40.591Z","updatedAt":"2020-01-20T20:02:02.711Z","orderId":"73","currency":"USD","total":299.99,"status":"pendingShipment","userId":"dee3ca08-27de-495c-8738-060029a58449"}
```

Where: 
* createdAt - time of the order creation in ISO 8601 standard
* updatedAt - time of the latest order status update in ISO 8601
* orderId - unique identifier of the order in your CRM system or website database. For other businesses it might be lead identifier or any other unique record identifier.
* currency - order currency code
* total - Total cost of the order
* status - Order status by the time of  (e.g. "created", "shipped", "cancelled", "pendingPayment", "pendingShipment", "returned")
* userId - unique identifier of the user that made an order
> Note: the structure is provided as a reference - you can add any other field that you need for your purposes.

## Step 2: Enabling feed import in SegmentStream
1. Go to [SegmentStream admin page ▸](https://admin.segmentstream.com)
2. Open **Data Sources ▸ Add**
3. Select **JSON Feed**
4. Fill in Basic Auth credentials
5. Fill in the fields:
    * **Feed URL** - fill in URL where your feed can be found (don't enter date parameter)
    * **Destination table name** - BigQuery table name that will contain imported feed data
6. If you use date  parameter and generate daily record updates enable option **Partition table by date**

Congratulations! During the next 24 hours your feed data will be uploaded to the corresponding BigQuery table.